{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'raise', 'over': 'raise', 'under': 'raise', 'invalid': 'raise'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run prepare_data.ipynb\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = read_csv_int('vornamen_as_features')\n",
    "test_data = read_csv_int('vornamen_test_data')\n",
    "\n",
    "training_data = np.array([np.array(xi) for xi in training_data])\n",
    "test_data = np.array([np.array(xi) for xi in test_data])\n",
    "\n",
    "data = training_data[:, :-1] # for last column\n",
    "expected_results = training_data[:, -1] # for all but last column\n",
    "\n",
    "test = test_data[:, :-1]\n",
    "expected_test = test_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    return x*(1-x) if derivative else 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12858, 12858)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (12858,12858) and (4,1) not aligned: 12858 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-01e896085768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m#return ['W1':W1,'W2':W2], costs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-168-01e896085768>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(X, y, nn_hdim, num_passes, print_loss)\u001b[0m\n\u001b[1;32m     39\u001b[0m         (np.dot(\n\u001b[1;32m     40\u001b[0m             \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mW2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         ) * sigmoid(layer1, True))\n\u001b[1;32m     43\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (12858,12858) and (4,1) not aligned: 12858 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "nn_input_dim = len(data[0]) # input layer dimensionality\n",
    "nn_output_dim = 1 # output layer dimensionality\n",
    "# Gradient descent parameters (I picked these by hand)\n",
    "epsilon = 0.7 # learning rate for gradient descent\n",
    "reg_lambda = 0 # regularization strength\n",
    "\n",
    "# This function learns parameters for the neural network and returns the model.\n",
    "# - nn_hdim: Number of nodes in the hidden layer\n",
    "# - num_passes: Number of passes through the training data for gradient descent\n",
    "# - print_loss: If True, print the loss every 1000 iterations\n",
    "def build_model(X, y, nn_hdim, num_passes=5000, print_loss=False):\n",
    "    # Initialize the parameters to random values. We need to learn these.\n",
    "    num_examples = len(X) # training set size\n",
    "    W1 = np.random.randn(nn_input_dim, nn_hdim)\n",
    "    W2 = np.random.randn(nn_hdim, nn_output_dim)\n",
    " \n",
    "    #print(W1)\n",
    "    #print(W2)\n",
    "    # This is what we return at the end\n",
    "    model = {}\n",
    "    costs = []\n",
    "     \n",
    "    # Gradient descent. For each batch...\n",
    "#    for i in range(0, num_passes):\n",
    "    # Forward propagation\n",
    "    layer1 = sigmoid(np.dot(X,W1))\n",
    "    output = sigmoid(np.dot(layer1,W2))\n",
    "    \n",
    "    some_calc_1 = (y - output)\n",
    "    print(some_calc_1.shape)\n",
    "    \n",
    "    # back propagation\n",
    "    d_weights2 = np.dot(\n",
    "        layer1.T,\n",
    "        some_calc_1\n",
    "    )\n",
    "    d_weights1 = np.dot(\n",
    "        X.T,\n",
    "        (np.dot(\n",
    "            2*(y - output) * sigmoid(output, True),\n",
    "            W2\n",
    "        ) * sigmoid(layer1, True))\n",
    "    )\n",
    "\n",
    "    W1 += dweights2\n",
    "    W2 += dweights1\n",
    "    print(W1)\n",
    "    print(W2)\n",
    "     \n",
    "    #return ['W1':W1,'W2':W2], costs\n",
    "\n",
    "trained_model, costs = build_model(data, expected_results, 4, print_loss=True)\n",
    "\n",
    "fig = plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(trained_model, test)\n",
    "\n",
    "correct = 0\n",
    "\n",
    "print(trained_model['W1'])\n",
    "print(trained_model['b1'])\n",
    "print(trained_model['W2'])\n",
    "print(trained_model['b2'])\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == expected_test[i]:\n",
    "        correct += 1\n",
    "\n",
    "print((correct * 100) / len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
